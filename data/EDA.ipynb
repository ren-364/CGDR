{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read from MIMIC csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'med_process' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 219>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;66;03m# drug-drug interactions can be down https://www.dropbox.com/s/8os4pd2zmp2jemd/drug-DDI.csv?dl=0\u001b[39;00m\n\u001b[0;32m    216\u001b[0m ddi_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mprojects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdrug-DDI.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 219\u001b[0m med_pd \u001b[38;5;241m=\u001b[39m \u001b[43mmed_process\u001b[49m(med_file)\n\u001b[0;32m    220\u001b[0m med_pd_lg2 \u001b[38;5;241m=\u001b[39m process_visit_lg2(med_pd)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    221\u001b[0m med_pd \u001b[38;5;241m=\u001b[39m med_pd\u001b[38;5;241m.\u001b[39mmerge(\n\u001b[0;32m    222\u001b[0m         med_pd_lg2[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUBJECT_ID\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[0;32m    223\u001b[0m         on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUBJECT_ID\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    224\u001b[0m     )\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'med_process' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def process_procedure():\n",
    "    pro_pd = pd.read_csv(procedure_file, dtype={'ICD9_CODE': 'category'})\n",
    "    pro_pd.drop(columns=['ROW_ID'], inplace=True)\n",
    "    pro_pd.drop_duplicates(inplace=True)\n",
    "    pro_pd.sort_values(by=['SUBJECT_ID', 'HADM_ID', 'SEQ_NUM'], inplace=True)\n",
    "    pro_pd.drop(columns=['SEQ_NUM'], inplace=True)\n",
    "    pro_pd.drop_duplicates(inplace=True)\n",
    "    pro_pd.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return pro_pd\n",
    "\n",
    "\n",
    "def process_med():\n",
    "    med_pd = pd.read_csv(med_file, dtype={'NDC':'category'})\n",
    "    med_pd.drop(columns=['ROW_ID','DRUG_TYPE','DRUG_NAME_POE','DRUG_NAME_GENERIC',\n",
    "                     'FORMULARY_DRUG_CD','GSN','PROD_STRENGTH','DOSE_VAL_RX',\n",
    "                     'DOSE_UNIT_RX','FORM_VAL_DISP','FORM_UNIT_DISP','FORM_UNIT_DISP',\n",
    "                      'ROUTE','ENDDATE','DRUG'], axis=1, inplace=True)\n",
    "    med_pd.drop(index = med_pd[med_pd['NDC'] == '0'].index, axis=0, inplace=True)\n",
    "    med_pd.fillna(method='pad', inplace=True)\n",
    "    med_pd.dropna(inplace=True)\n",
    "    med_pd.drop_duplicates(inplace=True)\n",
    "    med_pd['ICUSTAY_ID'] = med_pd['ICUSTAY_ID'].astype('int64')\n",
    "    med_pd['STARTDATE'] = pd.to_datetime(med_pd['STARTDATE'], format='%Y-%m-%d %H:%M:%S')    \n",
    "    med_pd.sort_values(by=['SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID', 'STARTDATE'], inplace=True)\n",
    "    med_pd = med_pd.reset_index(drop=True)\n",
    "    med_pd = med_pd.reset_index(drop=True)\n",
    "    med_pd = med_pd.drop(columns=['ICUSTAY_ID'])\n",
    "    med_pd = med_pd.drop_duplicates()\n",
    "    med_pd = med_pd.reset_index(drop=True) \n",
    "    \n",
    "    return med_pd\n",
    "def process_visit_lg2(med_pd):\n",
    "    a = med_pd[['SUBJECT_ID', 'HADM_ID']].groupby(\n",
    "        by='SUBJECT_ID'\n",
    "    )['HADM_ID'].unique().reset_index()\n",
    "    a['HADM_ID_Len'] = a['HADM_ID'].map(lambda x: len(x))\n",
    "    a = a[a['HADM_ID_Len'] > 1]\n",
    "    return a\n",
    "\n",
    "def process_diag():\n",
    "    diag_pd = pd.read_csv(diag_file)\n",
    "    diag_pd.dropna(inplace=True)\n",
    "    diag_pd.drop(columns=['SEQ_NUM', 'ROW_ID'], inplace=True)\n",
    "    diag_pd.drop_duplicates(inplace=True)\n",
    "    diag_pd.sort_values(by=['SUBJECT_ID', 'HADM_ID'], inplace=True)\n",
    "    diag_pd = diag_pd.reset_index(drop=True)\n",
    "\n",
    "    def filter_2000_most_diag(diag_pd):\n",
    "        diag_count = diag_pd.groupby(by=['ICD9_CODE']).size().\\\n",
    "            reset_index().rename(columns={0: 'count'}).\\\n",
    "            sort_values(by=['count'], ascending=False).reset_index(drop=True)\n",
    "        diag_pd = diag_pd[diag_pd['ICD9_CODE'].isin(\n",
    "            diag_count.loc[:1999, 'ICD9_CODE']\n",
    "        )]\n",
    "\n",
    "        return diag_pd.reset_index(drop=True)\n",
    "\n",
    "    diag_pd = filter_2000_most_diag(diag_pd)\n",
    "    return diag_pd\n",
    "\n",
    "def ndc2atc4(med_pd):\n",
    "    with open(ndc2rxnorm_file, 'r') as f:\n",
    "        ndc2rxnorm = eval(f.read())\n",
    "    med_pd['RXCUI'] = med_pd['NDC'].map(ndc2rxnorm)\n",
    "    med_pd.dropna(inplace=True)\n",
    "\n",
    "    rxnorm2atc = pd.read_csv(ndc2atc_file)\n",
    "    rxnorm2atc = rxnorm2atc.drop(columns=['YEAR','MONTH','NDC'])\n",
    "    rxnorm2atc.drop_duplicates(subset=['RXCUI'], inplace=True)\n",
    "    med_pd.drop(index = med_pd[med_pd['RXCUI'].isin([''])].index, axis=0, inplace=True)\n",
    "    \n",
    "    med_pd['RXCUI'] = med_pd['RXCUI'].astype('int64')\n",
    "    med_pd = med_pd.reset_index(drop=True)\n",
    "    med_pd = med_pd.merge(rxnorm2atc, on=['RXCUI'])\n",
    "    med_pd.drop(columns=['NDC', 'RXCUI'], inplace=True)\n",
    "    med_pd = med_pd.rename(columns={'ATC4':'NDC'})\n",
    "    med_pd['NDC'] = med_pd['NDC'].map(lambda x: x[:4])\n",
    "    med_pd = med_pd.drop_duplicates()    \n",
    "    med_pd = med_pd.reset_index(drop=True)\n",
    "    return med_pd\n",
    "\n",
    "def filter_1000_most_pro(pro_pd):\n",
    "    pro_count = pro_pd.groupby(by=['ICD9_CODE']).size().reset_index().\\\n",
    "        rename(columns={0: 'count'}).\\\n",
    "        sort_values(by=['count'], ascending=False).reset_index(drop=True)\n",
    "    pro_pd = pro_pd[pro_pd['ICD9_CODE'].isin(\n",
    "        pro_count.loc[:1000, 'ICD9_CODE']\n",
    "    )]\n",
    "\n",
    "    return pro_pd.reset_index(drop=True)\n",
    "\n",
    "def filter_300_most_med(med_pd):\n",
    "    med_count = med_pd.groupby(by=['NDC']).size().reset_index().\\\n",
    "        rename(columns={0: 'count'}).\\\n",
    "        sort_values(by=['count'], ascending=False).reset_index(drop=True)\n",
    "    med_pd = med_pd[med_pd['NDC'].isin(med_count.loc[:299, 'NDC'])]\n",
    "\n",
    "    return med_pd.reset_index(drop=True)\n",
    "\n",
    "def process_all(med_pd, diag_pd, pro_pd, demo_pd):\n",
    "    med_pd_key = med_pd[['SUBJECT_ID', 'HADM_ID']].drop_duplicates()\n",
    "    diag_pd_key = diag_pd[['SUBJECT_ID', 'HADM_ID']].drop_duplicates()\n",
    "    pro_pd_key = pro_pd[['SUBJECT_ID', 'HADM_ID']].drop_duplicates()\n",
    "\n",
    "    combined_key = med_pd_key.merge(\n",
    "        diag_pd_key, on=['SUBJECT_ID', 'HADM_ID'], how='inner')\n",
    "    combined_key = combined_key.merge(\n",
    "        pro_pd_key, on=['SUBJECT_ID', 'HADM_ID'], how='inner')\n",
    "\n",
    "    diag_pd = diag_pd.merge(\n",
    "        combined_key, on=['SUBJECT_ID', 'HADM_ID'], how='inner')\n",
    "    med_pd = med_pd.merge(\n",
    "        combined_key, on=['SUBJECT_ID', 'HADM_ID'], how='inner')\n",
    "    pro_pd = pro_pd.merge(\n",
    "        combined_key, on=['SUBJECT_ID', 'HADM_ID'], how='inner')\n",
    "\n",
    "    # flatten and merge\n",
    "    diag_pd = diag_pd.groupby(by=['SUBJECT_ID', 'HADM_ID'])['ICD9_CODE'].\\\n",
    "        unique().reset_index()\n",
    "    med_pd = med_pd.groupby(by=['SUBJECT_ID', 'HADM_ID'])['NDC'].\\\n",
    "        unique().reset_index()\n",
    "    pro_pd = pro_pd.groupby(by=['SUBJECT_ID', 'HADM_ID'])['ICD9_CODE'].\\\n",
    "        unique().reset_index().rename(columns={'ICD9_CODE': 'PRO_CODE'})\n",
    "    med_pd['NDC'] = med_pd['NDC'].map(lambda x: list(x))\n",
    "    pro_pd['PRO_CODE'] = pro_pd['PRO_CODE'].map(lambda x: list(x))\n",
    "    data = diag_pd.merge(med_pd, on=['SUBJECT_ID', 'HADM_ID'], how='inner')\n",
    "    data = data.merge(pro_pd, on=['SUBJECT_ID', 'HADM_ID'], how='inner')\n",
    "    data = data.merge(demo_pd, on='HADM_ID', how='inner')\n",
    "    # data['ICD9_CODE_Len'] = data['ICD9_CODE'].map(lambda x: len(x))\n",
    "    data['NDC_Len'] = data['NDC'].map(lambda x: len(x))\n",
    "    return data\n",
    "\n",
    "def statistics():\n",
    "    print('#patients ', data['SUBJECT_ID'].unique().shape)\n",
    "    print('#clinical events ', len(data))\n",
    "    \n",
    "    diag = data['ICD9_CODE'].values\n",
    "    med = data['NDC'].values\n",
    "    pro = data['PRO_CODE'].values\n",
    "    \n",
    "    unique_diag = set([j for i in diag for j in list(i)])\n",
    "    unique_med = set([j for i in med for j in list(i)])\n",
    "    unique_pro = set([j for i in pro for j in list(i)])\n",
    "    \n",
    "    print('#diagnosis ', len(unique_diag))\n",
    "    print('#med ', len(unique_med))\n",
    "    print('#procedure', len(unique_pro))\n",
    "    \n",
    "    avg_diag = 0\n",
    "    avg_med = 0\n",
    "    avg_pro = 0\n",
    "    max_diag = 0\n",
    "    max_med = 0\n",
    "    max_pro = 0\n",
    "    cnt = 0\n",
    "    max_visit = 0\n",
    "    avg_visit = 0\n",
    "\n",
    "    for subject_id in data['SUBJECT_ID'].unique():\n",
    "        item_data = data[data['SUBJECT_ID'] == subject_id]\n",
    "        x = []\n",
    "        y = []\n",
    "        z = []\n",
    "        visit_cnt = 0\n",
    "        for index, row in item_data.iterrows():\n",
    "            visit_cnt += 1\n",
    "            cnt += 1\n",
    "            x.extend(list(row['ICD9_CODE']))\n",
    "            y.extend(list(row['NDC']))\n",
    "            z.extend(list(row['PRO_CODE']))\n",
    "        x = set(x)\n",
    "        y = set(y)\n",
    "        z = set(z)\n",
    "        avg_diag += len(x)\n",
    "        avg_med += len(y)\n",
    "        avg_pro += len(z)\n",
    "        avg_visit += visit_cnt\n",
    "        if len(x) > max_diag:\n",
    "            max_diag = len(x)\n",
    "        if len(y) > max_med:\n",
    "            max_med = len(y) \n",
    "        if len(z) > max_pro:\n",
    "            max_pro = len(z)\n",
    "        if visit_cnt > max_visit:\n",
    "            max_visit = visit_cnt\n",
    "        \n",
    "\n",
    "        \n",
    "    print('#avg of diagnoses ', avg_diag/ cnt)\n",
    "    print('#avg of medicines ', avg_med/ cnt)\n",
    "    print('#avg of procedures ', avg_pro/ cnt)\n",
    "    print('#avg of vists ', avg_visit/ len(data['SUBJECT_ID'].unique()))\n",
    "    \n",
    "\n",
    "    print('#max of diagnoses ', max_diag)\n",
    "    print('#max of medicines ', max_med)\n",
    "    print('#max of procedures ', max_pro)\n",
    "    print('#max of visit ', max_visit)\n",
    "    \n",
    "# files can be downloaded from https://mimic.physionet.org/gettingstarted/dbsetup/\n",
    "med_file = 'F:\\projects\\PRESCRIPTIONS.csv'\n",
    "diag_file = 'F:\\projects\\DIAGNOSES_ICD.csv'\n",
    "procedure_file = 'F:\\projects\\PROCEDURES_ICD.csv'\n",
    "\n",
    "med_structure_file = 'idx2SMILES.pkl'\n",
    "# drug code mapping files (already in ./data/)\n",
    "ndc2atc_file = 'ndc2atc_level4.csv' \n",
    "cid_atc = 'drug-atc.csv'\n",
    "ndc2rxnorm_file = 'ndc2rxnorm_mapping.txt'\n",
    "\n",
    "# drug-drug interactions can be down https://www.dropbox.com/s/8os4pd2zmp2jemd/drug-DDI.csv?dl=0\n",
    "ddi_file = 'F:\\projects\\drug-DDI.csv'\n",
    "\n",
    "    \n",
    "med_pd = med_process(med_file)\n",
    "med_pd_lg2 = process_visit_lg2(med_pd).reset_index(drop=True)\n",
    "med_pd = med_pd.merge(\n",
    "        med_pd_lg2[['SUBJECT_ID']],\n",
    "        on='SUBJECT_ID', how='inner'\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "med_pd = ndc2atc4(med_pd)\n",
    "NDCList = dill.load(open(med_structure_file, 'rb'))\n",
    "med_pd = med_pd[med_pd.NDC.isin(list(NDCList.keys()))]\n",
    "\n",
    "med_pd = filter_300_most_med(med_pd)\n",
    "\n",
    "diag_pd = diag_process(diag_file)\n",
    "\n",
    "pro_pd = procedure_process(procedure_file)\n",
    "\n",
    "data = combine_process(med_pd, diag_pd, pro_pd)   \n",
    "\n",
    "statistics()\n",
    "data.to_pickle('data_final.pkl')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 17, 92)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dill\n",
    "import pandas as pd\n",
    "class Voc(object):\n",
    "    def __init__(self):\n",
    "        self.idx2word = {}\n",
    "        self.word2idx = {}\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence:\n",
    "            if word not in self.word2idx:\n",
    "                self.idx2word[len(self.word2idx)] = word\n",
    "                self.word2idx[word] = len(self.word2idx)\n",
    "                \n",
    "def create_str_token_mapping(df):\n",
    "    diag_voc = Voc()\n",
    "    med_voc = Voc()\n",
    "    pro_voc = Voc()\n",
    "    ## only for DMNC\n",
    "#     diag_voc.add_sentence(['seperator', 'decoder_point'])\n",
    "#     med_voc.add_sentence(['seperator', 'decoder_point'])\n",
    "#     pro_voc.add_sentence(['seperator', 'decoder_point'])\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        diag_voc.add_sentence(row['ICD9_CODE'])\n",
    "        med_voc.add_sentence(row['NDC'])\n",
    "        pro_voc.add_sentence(row['PRO_CODE'])\n",
    "    \n",
    "    dill.dump(obj={'diag_voc':diag_voc, 'med_voc':med_voc ,'pro_voc':pro_voc}, file=open('voc_v1.pkl','wb'))\n",
    "    return diag_voc, med_voc, pro_voc\n",
    "\n",
    "def create_patient_record(df, diag_voc, med_voc, pro_voc):\n",
    "    records = [] # (patient, code_kind:3, codes)  code_kind:diag, proc, med\n",
    "    for subject_id in df['SUBJECT_ID'].unique():\n",
    "        item_df = df[df['SUBJECT_ID'] == subject_id]\n",
    "        patient = []\n",
    "        for index, row in item_df.iterrows():\n",
    "            admission = []\n",
    "            admission.append([diag_voc.word2idx[i] for i in row['ICD9_CODE']])\n",
    "            admission.append([pro_voc.word2idx[i] for i in row['PRO_CODE']])\n",
    "            admission.append([med_voc.word2idx[i] for i in row['NDC']])\n",
    "            patient.append(admission)\n",
    "        records.append(patient) \n",
    "    dill.dump(obj=records, file=open('records_v1.pkl', 'wb'))\n",
    "    return records\n",
    "        \n",
    "    \n",
    "#path='data_final.pkl'\n",
    "#df = pd.read_pickle(path)\n",
    "diag_voc, med_voc, pro_voc = create_str_token_mapping(df)\n",
    "records = create_patient_record(df, diag_voc, med_voc, pro_voc)\n",
    "len(diag_voc.idx2word), len(med_voc.idx2word), len(pro_voc.idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_list(lst):\n",
    "    # 保留每个字符串的前两位并去除重复值\n",
    "    return list(set([item[:2] for item in lst]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>NDC</th>\n",
       "      <th>PRO_CODE</th>\n",
       "      <th>NDC_Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>161087</td>\n",
       "      <td>[4239, 5119, 78551, 4589, 311, 7220, 71946, 2724]</td>\n",
       "      <td>[N02B, A01A, A02B, A06A, B05C, A12A, A12C, C01...</td>\n",
       "      <td>[3731, 8872, 3893]</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>194023</td>\n",
       "      <td>[7455, 45829, V1259, 2724]</td>\n",
       "      <td>[N02B, A01A, A02B, A06A, A12A, B05C, A12C, C01...</td>\n",
       "      <td>[3571, 3961, 8872]</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>109451</td>\n",
       "      <td>[41071, 78551, 5781, 5849, 40391, 4280, 4592, ...</td>\n",
       "      <td>[A06A, B05C, C07A, A12B, C03C, A12A, A02A, J01...</td>\n",
       "      <td>[0066, 3761, 3950, 3606, 0042, 0047, 3895, 399...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>111970</td>\n",
       "      <td>[0388, 78552, 40391, 42731, 70709, 5119, 6823,...</td>\n",
       "      <td>[N02B, A06A, B05C, A12C, A07A, A02A, B01A, N06...</td>\n",
       "      <td>[3995, 8961, 0014]</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>124321</td>\n",
       "      <td>[2252, 3485, 78039, 4241, 4019, 2720, 2724, V4...</td>\n",
       "      <td>[B05C, A07A, C07A, A06A, N02B, C02D, B01A, A02...</td>\n",
       "      <td>[0151]</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID  HADM_ID                                          ICD9_CODE  \\\n",
       "0          17   161087  [4239, 5119, 78551, 4589, 311, 7220, 71946, 2724]   \n",
       "1          17   194023                         [7455, 45829, V1259, 2724]   \n",
       "2          21   109451  [41071, 78551, 5781, 5849, 40391, 4280, 4592, ...   \n",
       "3          21   111970  [0388, 78552, 40391, 42731, 70709, 5119, 6823,...   \n",
       "4          23   124321  [2252, 3485, 78039, 4241, 4019, 2720, 2724, V4...   \n",
       "\n",
       "                                                 NDC  \\\n",
       "0  [N02B, A01A, A02B, A06A, B05C, A12A, A12C, C01...   \n",
       "1  [N02B, A01A, A02B, A06A, A12A, B05C, A12C, C01...   \n",
       "2  [A06A, B05C, C07A, A12B, C03C, A12A, A02A, J01...   \n",
       "3  [N02B, A06A, B05C, A12C, A07A, A02A, B01A, N06...   \n",
       "4  [B05C, A07A, C07A, A06A, N02B, C02D, B01A, A02...   \n",
       "\n",
       "                                            PRO_CODE  NDC_Len  \n",
       "0                                 [3731, 8872, 3893]       16  \n",
       "1                                 [3571, 3961, 8872]       17  \n",
       "2  [0066, 3761, 3950, 3606, 0042, 0047, 3895, 399...       24  \n",
       "3                                 [3995, 8961, 0014]       20  \n",
       "4                                             [0151]       17  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ICD9_CODE'] = df['ICD9_CODE'].apply(process_list)\n",
    "df['NDC'] = df['NDC'].apply(process_list)\n",
    "df['PRO_CODE'] = df['PRO_CODE'].apply(process_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>NDC</th>\n",
       "      <th>PRO_CODE</th>\n",
       "      <th>NDC_Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>161087</td>\n",
       "      <td>[27, 45, 51, 78, 42, 71, 31, 72]</td>\n",
       "      <td>[A0, C0, A1, B0, N0, M0]</td>\n",
       "      <td>[88, 37, 38]</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>194023</td>\n",
       "      <td>[74, 27, 45, V1]</td>\n",
       "      <td>[A0, C0, A1, B0, N0, M0]</td>\n",
       "      <td>[35, 88, 39]</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>109451</td>\n",
       "      <td>[27, 45, 11, V1, 58, 78, 57, 50, 25, 41, 42, 4...</td>\n",
       "      <td>[A0, C0, D0, A1, B0, J0, C1, N0]</td>\n",
       "      <td>[97, 88, 00, 37, 99, 39, 36, 38]</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>111970</td>\n",
       "      <td>[27, 00, 99, 57, 41, 43, 51, 03, 78, 44, 40, 2...</td>\n",
       "      <td>[A0, C0, H0, R0, A1, B0, J0, C1, N0]</td>\n",
       "      <td>[00, 89, 39]</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>124321</td>\n",
       "      <td>[27, 22, V1, 78, 34, V4, 42, 40]</td>\n",
       "      <td>[A0, C0, H0, A1, B0, C1, N0]</td>\n",
       "      <td>[01]</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID  HADM_ID                                          ICD9_CODE  \\\n",
       "0          17   161087                   [27, 45, 51, 78, 42, 71, 31, 72]   \n",
       "1          17   194023                                   [74, 27, 45, V1]   \n",
       "2          21   109451  [27, 45, 11, V1, 58, 78, 57, 50, 25, 41, 42, 4...   \n",
       "3          21   111970  [27, 00, 99, 57, 41, 43, 51, 03, 78, 44, 40, 2...   \n",
       "4          23   124321                   [27, 22, V1, 78, 34, V4, 42, 40]   \n",
       "\n",
       "                                    NDC                          PRO_CODE  \\\n",
       "0              [A0, C0, A1, B0, N0, M0]                      [88, 37, 38]   \n",
       "1              [A0, C0, A1, B0, N0, M0]                      [35, 88, 39]   \n",
       "2      [A0, C0, D0, A1, B0, J0, C1, N0]  [97, 88, 00, 37, 99, 39, 36, 38]   \n",
       "3  [A0, C0, H0, R0, A1, B0, J0, C1, N0]                      [00, 89, 39]   \n",
       "4          [A0, C0, H0, A1, B0, C1, N0]                              [01]   \n",
       "\n",
       "   NDC_Len  \n",
       "0       15  \n",
       "1       16  \n",
       "2       23  \n",
       "3       19  \n",
       "4       17  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDI & Construct EHR Adj and DDI Adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import dill\n",
    "\n",
    "# atc -> cid\n",
    "ddi_file = 'F:\\projects\\drug-DDI.csv'\n",
    "cid_atc = 'drug-atc.csv'\n",
    "voc_file = 'voc_final.pkl'\n",
    "data_path = 'records_final.pkl'\n",
    "TOPK = 40 # topk drug-drug interaction\n",
    "\n",
    "records =  dill.load(open(data_path, 'rb'))\n",
    "cid2atc_dic = defaultdict(set)\n",
    "med_voc = dill.load(open(voc_file, 'rb'))['med_voc']\n",
    "med_voc_size = len(med_voc.idx2word)\n",
    "med_unique_word = [med_voc.idx2word[i] for i in range(med_voc_size)]\n",
    "atc3_atc4_dic = defaultdict(set)\n",
    "for item in med_unique_word:\n",
    "    atc3_atc4_dic[item[:4]].add(item)\n",
    "    \n",
    "\n",
    "with open(cid_atc, 'r') as f:\n",
    "    for line in f:\n",
    "        line_ls = line[:-1].split(',')\n",
    "        cid = line_ls[0]\n",
    "        atcs = line_ls[1:]\n",
    "        for atc in atcs:\n",
    "            if len(atc3_atc4_dic[atc[:4]]) != 0:\n",
    "                cid2atc_dic[cid].add(atc[:4])\n",
    "            \n",
    "# ddi load\n",
    "ddi_df = pd.read_csv(ddi_file)\n",
    "# fliter sever side effect \n",
    "ddi_most_pd = ddi_df.groupby(by=['Polypharmacy Side Effect', 'Side Effect Name']).size().reset_index().rename(columns={0:'count'}).sort_values(by=['count'],ascending=False).reset_index(drop=True)\n",
    "ddi_most_pd = ddi_most_pd.iloc[-TOPK:,:]\n",
    "# ddi_most_pd = pd.DataFrame(columns=['Side Effect Name'], data=['as','asd','as'])\n",
    "fliter_ddi_df = ddi_df.merge(ddi_most_pd[['Side Effect Name']], how='inner', on=['Side Effect Name'])\n",
    "ddi_df = fliter_ddi_df[['STITCH 1','STITCH 2']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# weighted ehr adj \n",
    "ehr_adj = np.zeros((med_voc_size, med_voc_size))\n",
    "for patient in records:\n",
    "    for adm in patient:\n",
    "        med_set = adm[2]\n",
    "        for i, med_i in enumerate(med_set):\n",
    "            for j, med_j in enumerate(med_set):\n",
    "                if j<=i:\n",
    "                    continue\n",
    "                ehr_adj[med_i, med_j] = 1\n",
    "                ehr_adj[med_j, med_i] = 1\n",
    "dill.dump(ehr_adj, open('ehr_adj_final.pkl', 'wb'))  \n",
    "\n",
    "\n",
    "\n",
    "# ddi adj\n",
    "ddi_adj = np.zeros((med_voc_size,med_voc_size))\n",
    "for index, row in ddi_df.iterrows():\n",
    "    # ddi\n",
    "    cid1 = row['STITCH 1']\n",
    "    cid2 = row['STITCH 2']\n",
    "    \n",
    "    # cid -> atc_level3\n",
    "    for atc_i in cid2atc_dic[cid1]:\n",
    "        for atc_j in cid2atc_dic[cid2]:\n",
    "            \n",
    "            # atc_level3 -> atc_level4\n",
    "            for i in atc3_atc4_dic[atc_i]:\n",
    "                for j in atc3_atc4_dic[atc_j]:\n",
    "                    if med_voc.word2idx[i] != med_voc.word2idx[j]:\n",
    "                        ddi_adj[med_voc.word2idx[i], med_voc.word2idx[j]] = 1\n",
    "                        ddi_adj[med_voc.word2idx[j], med_voc.word2idx[i]] = 1\n",
    "dill.dump(ddi_adj, open('ddi_A_final.pkl', 'wb')) \n",
    "                        \n",
    "print('complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
